= Spring Cloud
:toc: left
:imagesdir: images

ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

== Distributed tracing

One of the problems developers encounter as their microservice apps grow, is how to be able to trace requests that propagate from one microservice to the next. It can be quite daunting to figure out how a requests travels through the app, especially when you may not have any insight into the implementation of the microservice you are calling.

Distributed Tracing is crucial for troubleshooting and understanding microservices. It is very useful when we need to track the request passing through multiple microservices. Distributed Tracing can be also be used to measure the performance of the microservices.

https://spring.io/projects/spring-cloud-sleuth[Spring Cloud Sleuth] is meant to help with this. It introduces unique IDs to your logging which are consistent between microservice calls. This makes it possible to find how a single request travels from one microservice to the next.

=== Adding Sleuth tracing
To add Sleuth tracing to our applications, we need to follow these steps.

[quote]
____
. Add dependency to `items-service/pom.xml`, `reviews-service/pom.xml`, `webapi/pom.xml` and `gateway/pom.xml`

[source,xml]
----
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-sleuth</artifactId>
    </dependency>
----

. Restart the above applications
.. Wait for all applications to come up and start responding

. Fetch items from webapi, `curl http://localhost:20202/webapi/items | jq` (or `curl http://localhost:20202/webapi/items -u frank:abc | jq` if security is enabled)
.. (if webapi/items responds with an error, call it again)

. Look at the logs:
+
Gateway logs does not show any traces because we are not logging anything. But the Gateway still adds a trace to the request's header before sending it downstream.
+
The `webapi`, `items-service` and `reviews-service` logs should look something like this:
+
[source,sql]
----
2019-10-06 16:19:40.232  INFO [webapi,dcf4bfcb6aa3dacd,d6fb394b0254be13,false] 35401 --- [nio-8100-exec-2] c.a.t.webapi.web.WebApiController : /webapi/items called

2019-10-06 16:19:40.155  INFO [items-service,dcf4bfcb6aa3dacd,a2c5fc96f7806cfa,false] 35448 --- [nio-8081-exec-4] c.a.t.i.web.ItemsServiceController : Returning ItemDto(id=1, name=Spoon, port=8081)

2019-10-06 16:19:40.223  INFO [reviews-service,dcf4bfcb6aa3dacd,e8e3fa3ca2a57903,false] 35399 --- [nio-9090-exec-2] c.a.t.r.web.ReviewsServiceController : Returning ReviewDto(id=2, type=item, typeId=1, rating=3, ratingMin=1, ratingMax=5, comment=The spoon works until you turn it upside down, then it becomes useless, port=9090)
----
+
Look at the logging statements and notice that the trace ids are the same (dcf4bfcb6aa3dacd) but the span ids are different. The trace ids are what is going to allow you to trace a request as it travels from one service to the next. The span ids are different because we have three different “units of work” occurring, one for each request.
____

[TIP]
All this additional information in your logs is great but making sense of it all can be hard. Using something like the ELK stack to collect and analyze the logs from your microservices can be quite helpful. By using the trace id you can easily search across all the collected logs and see how the request passed from one microservice to the next. Log aggregation is an important topic, but we will not explore it further here.

What if you want to see timing information, perhaps if some service is slow or errors occur in your overall microservices setup? Where does a request spend most time before responding back to client? To answer these questions, we will have a look at _Zipkin_.

=== Starting a Zipkin server
Zipkin is an open source distributed tracing system based on _Dapper_ from Google. They built Dapper to provide Google’s developers with more information about the behavior of complex distributed systems. Zipkin helps gather timing data needed when monitoring and troubleshooting latency problems in service architectures. Features include both the collection and lookup of this data.

So in our context we would like to send the tracing data created by Sleuth to a https://zipkin.io[Zipkin] server, where it gets stored together with timing information for later use.

It is possible to setup a Zipkin in a similar way as we did with Eureka, by adding a new Spring Boot project with some carefully selected dependencies, but we will not do that here (because it will be a repetition of the same process of adding Spring Boot components as you have done so many times now, it's getting boring, right?). Instead we will start a Docker container with a Zipkin server already setup for use.

[quote]
____
. Start Zipkin server
+
[source,bash]
----
docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin
----
+
. When started, you should be able to access the Zipkin UI at http://localhost:9411
____

=== Registering Client Application With Zipkin Server

We do now have a Zipkin server up and running. Next step is to start sending the Sleuth tracing information from our apps to it.

[quote]
____
. Add the url to Zipkin server to relevant application configs in `config-server`.
+
Add this config snippet
+
[source,yml]
----
spring:
  zipkin:
    base-url: http://localhost:9411
----
+
to
+
* `config-server/src/main/resources/gateway.yml`
* `config-server/src/main/resources/items-service.yml`
* `config-server/src/main/resources/reviews-service.yml`
* `config-server/src/main/resources/webapi.yml`

. Restart `config-server`

. Let's enable our applications to start sending tracing information to the Zipkin server.
+
Add dependency to `items-service/pom.xml`, `reviews-service/pom.xml`, `webapi/pom.xml` and `gateway/pom.xml`
+
[source,xml]
----
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-zipkin</artifactId>
    </dependency>
----
+
In addition, we need to tell our applications how often we want to sample our logs to be exported to Zipkin. In our case, lets tell the apps that we want to sample everything. We can do this by creating a bean for the AlwaysSampler in each application's `@SpringBootApplication` class.

. In `GatewayApplication.java`, `WebapiApplication.java`, `ItemsServiceApplication.java`, and `ReviewsServiceApplication.java`, add this bean:
+
[source,java]
----
    ...

    @Bean
    public Sampler defaultSampler() {
        return Sampler.ALWAYS_SAMPLE;
    }

    ...
----
+
. Restart `GatewayApplication`, `WebapiApplication`, `ItemsServiceApplication`, and `ReviewsServiceApplication`
+
[TIP]
====
If using IntelliJ, you can mark all desired components and restart them in one go:

image::restart-many.png[]
====

. Access `curl http://localhost:20202/webapi/items | jq` (or `curl http://localhost:20202/webapi/items -u frank:abc | jq` if security is enabled)

. Look at the logs. You should see something close to this:
+
[source,sql]
----
2019-10-06 16:58:15.573  INFO [webapi,2b69e7f3219e242d,2f43183caa4e3e56,true] 35696 --- [nio-8100-exec-2] c.a.t.webapi.web.WebApiController : /webapi/items called

2019-10-06 16:58:15.582  INFO [items-service,2b69e7f3219e242d,557140b02d9c5ec4,true] 35699 --- [nio-8081-exec-3] c.a.t.i.web.ItemsServiceController : Returning ItemDto(id=1, name=Spoon, port=8081)

2019-10-06 16:58:15.599  INFO [reviews-service,2b69e7f3219e242d,19c04b9e12f5ac9f,true] 35701 --- [nio-9090-exec-2] c.a.t.r.web.ReviewsServiceController : Returning ReviewDto(id=2, type=item, typeId=1, rating=3, ratingMin=1, ratingMax=5, comment=The spoon works until you turn it upside down, then it becomes useless, port=9090)
----
+
It pretty much looks as the logs we saw before. Note however that the export flag in the Sleuth logging has changed from _false_ to _true_. This indicates that the tracing information is being sent to your Zipkin server.

. Open the Zipkin UI at http://localhost:9411

. Click on _Try Lens UI_ to get a more pleasant look and feel

. Click the magnifying glass
+
Here you should see tracing information for the endpoints involved, with timing info on how long each operation took. Clicking a row will show you all the details collected from the Sleuth logs including timing information for the particular request.

. Click on a row, then click on one of the services, like _reviews-service_.
+
At the bottom you should see some familiar traceIds and spanIds (if you compare them to the console logs).
____

This marks the end of the tracing example. Good work! In fact, it is almost the end of the whole session. The last thing for us to do before we leave is to quickly summarize what we have been doing.

<<09-end-of-the-road.adoc#,Nextup: Wrapping up>>

