= Containerization
:toc: left
:imagesdir: images

ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

== Intro
This section will touch upon the concept of containerizing microservices, or in other words, make them run in Docker. Doing so will give us a couple of benefits.

Development ease::
By now we do have a set of services that can be started independently, but they must be run together for the whole application to work. Although each service can be started as we have done so far, manually or via Intellij, seen from a development perspective this becomes rather cumbersome in the long run.
+
In this tutorial we have pretty much worked on all services at once. During real development work it is probably more realistic to say that we work on a single service, but where we need the other ones up and running as well. At least when we test the integration locally between services, or when we need to verify that a service chain works as intended when we change something.
+
What we need is a way to quickly spin all services up and down as we see fit, so we can focus on development work.

QA and testing::
By containerizing the microservices it becomes easier to setup processes for integration, api and acceptance tests, like CI/CD pipelines and similar.

Prepared for Kubernetes deployment::
If we containerize our services, we are one step away to deploy them onto a Kubernetes platform. Kubernetes is a portable, extensible, open-source platform for managing containerized workloads and services. It is becoming increasingly popular to deploy and run applications in this way. The topic of Kubernetes is however large enough for it's own tutorial, so we will not continue this discussion here.

== Docker and Docker compose

The description at https://docs.docker.com/compose/ sums it all up rather neatly:

_"Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your applicationâ€™s services. Then, with a single command, you create and start all the services from your configuration."_

This means that `docker-compose` is a good fit for us since we do have a set of services that can be started independently, but which must be run together.

So what is needed to make `docker-compose` work? Well, basically this:

. Each service must be containerized, which essentially means that a `Dockerfile` needs to be added for every service. Luckily, this file does not need to be very complex, and even better, the same content can be universally used for all services.

. We must add a file `docker-compose.yml` where we define what makes up a complete application.

. Run it.

=== Good to know before we start

Previously in the tutorial we have started all services locally, on _localhost_. Since all services ran on the same machine, it was important to use different ports so they didn't conflict with each other. That became extra important when starting several instances of the same service (recall that we started `reviews-service` on localhost:9090 and localhost:9095, for example).

image::locally-run-services.png[]
_Diagram 1: Running directly on localhost, using ports to distinguish unique hostname:port combinations_


When we containerize the services and run them in Docker, each service will run in it's own container with a specific id (hostname) and an IP-address (internal to Docker). This means that if we start another instance of the same service, this will run in another container with another container id as hostname and another internal IP-address. In this case we don't need to rely on ports for uniqueness.

We will therefore change so that applications in containers always uses port 8080. When running `docker-compose` all services will be available via their hostname/ip-address. Some services will expose other ports than 8080, for example the _gateway_, which will expose 20202 as usual (so clients can reach it).

image::docker-run-services.png[]
_Diagram 2: Running as docker containers, using container id to distinguish unique hostname:port combinations_

=== Adding Dockerfile for each service

[quote]
____

. Start by creating a Dockerfile with this content:
+
[source,dockerfile]
----
FROM openjdk:8

EXPOSE 8080

ADD ./target/*.jar app.jar

ENTRYPOINT ["java","-jar","/app.jar"]
----
+
. Copy the `Dockerfile` to these projects:
+
* `config-server/Dockerfile`
* `gateway/Dockerfile`
* `items-service/Dockerfile`
* `reviews-service/Dockerfile`
* `service-discovery-server/Dockerfile`
* `webapi/Dockerfile`
+
[NOTE]
The dockerfile for each service exposes the same internal port, 8080. Certain services will change the mapping to this port later on in `docker-compose.yml`.
+
. Open `config-server/src/main/resources/boostrap.yml` and add this _docker_ profile at the end of the file
+
[source,yml]
----
---
spring:
  profiles: docker

server:
  port: 8080
----
+
. In the following files:

* `service-discovery-server/bootstrap.yml`
* `items-service/bootstrap.yml`
* `reviews-service/bootstrap.yml`
* `webapi/bootstrap.yml`
* `gateway/bootstrap.yml`
+
add this _docker_ profile at the end of the file
+
[source,yml]
----
---
spring:
  profiles: docker

  cloud:
    config:
      uri: http://config-server:8080
      fail-fast: true
----
+
[NOTE]
When starting in `spring.profiles.active=docker` mode, each service will call the config server using the hostname `config-server` (instead of localhost). The actual name `config-server` will get defined in the `docker-compose.yml`, which we will create shortly.
+
. In `config-server/src/main/resource/config`, add a new spring profile to each `yml` file:
+
[source,yml]
----
---
spring:
  profiles: docker

  zipkin:
    base-url: http://zipkin:9411

server:
  port: 8080

eureka:
  client:
    serviceUrl:
      defaultZone: http://service-discovery-server:8080/eureka/
----
+
This means that if we start each service with `spring.profiles.active=docker`, they will startup using port 8080. Again, certain services will eventually remap this port later on in `docker-compose.yml`.
____

=== Adding docker-compose.yml

Now it is time to do the composing. For this we need to have a file `docker-compose.yml` in place.

[quote]
____

. Create file `acorn-microservices-tutorial/docker-compose.yml`

. Add the below content (some brief explanations will follow directly below):
+
[source,yml]
----
version: '2.1'

services:
  config-server:
    build: config-server
    mem_limit: 350m
    ports:
      - "7777:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://config-server:8080/actuator/health"]
      interval: 5s
      timeout: 5s
      retries: 10
    environment:
      - SPRING_PROFILES_ACTIVE=docker,native

  service-discovery-server:
    build: service-discovery-server
    mem_limit: 350m
    depends_on:
      config-server:
        condition: service_healthy
    ports:
      - "8761:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://service-discovery-server:8080/actuator/health"]
      interval: 5s
      timeout: 5s
      retries: 10
    environment:
      - SPRING_PROFILES_ACTIVE=docker

  items-service:
    build: items-service
    mem_limit: 350m
    depends_on:
      config-server:
        condition: service_healthy
      service-discovery-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://items-service:8080/actuator/health"]
      interval: 5s
      timeout: 5s
      retries: 10
    environment:
      - SPRING_PROFILES_ACTIVE=docker

  reviews-service:
    build: reviews-service
    mem_limit: 350m
    depends_on:
      config-server:
        condition: service_healthy
      service-discovery-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://reviews-service:8080/actuator/health"]
      interval: 5s
      timeout: 5s
      retries: 10
    environment:
      - SPRING_PROFILES_ACTIVE=docker

  webapi:
    build: webapi
    mem_limit: 350m
    depends_on:
      config-server:
        condition: service_healthy
      service-discovery-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://webapi:8080/actuator/health"]
      interval: 5s
      timeout: 5s
      retries: 10
    environment:
      - SPRING_PROFILES_ACTIVE=docker

  gateway:
    build: gateway
    mem_limit: 350m
    depends_on:
      config-server:
        condition: service_healthy
      service-discovery-server:
        condition: service_healthy
    ports:
      - "20202:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://gateway:8080/actuator/health"]
      interval: 5s
      timeout: 5s
      retries: 10
    environment:
      - SPRING_PROFILES_ACTIVE=docker,localauth

  zipkin:
    image: openzipkin/zipkin
    mem_limit: 512m
    ports:
      - "9411:9411"
    environment:
      - STORAGE_TYPE=mem
----
+
Worth noting here:

* The root `services` has several childs, one for each of our microservices. Each service will get the name specified here, the container of `config-server` will be named _config-server_, and so on.

* The `build` attribute points to each service root directory, in which a `Dockerfile` exist. So if `build` is used, `docker-compose` will build a docker image (if it does not already exist, or if it has been changed).

* The `zipkin` service does not use `build`, instead it uses `image`, which means that `docker-compose` will pull that image and run it.

* The `config-server`, `service-discovery-server` and `gateway` maps their respective ports to 8080 (7777:8080, 8761:8080 and 20202:8080), this because they all use a fixed port to which other services or browser connects (they are not looked up via service discovery).

* The `items-service`, `reviews-service` and `webapi` does not map any ports at all. Instead they uses `environment` to set the variable `SPRING_PROFILES_ACTIVE=docker` (yet another way to specify a spring boot profile). This will eventually startup the services using port 8080, which we already exposed via the Dockerfile. Furthermore, these services will register themselves to `service-discovery-server` with their _hostname_ and port 8080. The actual hostname will be the container name or id given by Docker. So in short, the service discovery will be based on unique container names, which means that the ports can be 8080 for all services here, without any conflict.

* `depends_on` is a way to specify the startup order of the containers. We obviously need the `config-server` and `service-discovery-server` up and running before the other containers start calling them.
____

=== Run the whole application

[IMPORTANT]
====
If any services are running (via Intellij or command line), make sure to turn them off! Also remember to turn off the zipkin docker image, if running.

`docker rm -f zipkin`
====

With all above in place, we can now startup the complete application. It is possible to run the composed docker environment in detached mode:

[source,bash]
----
# Starting up in detached mode
docker-compose -f <compose-file.yml> up -d

# If the <compose-file.yml> is named docker-compose.yml, you don't need to specify the file
docker-compose up -d

# Tail the logs of all services
docker-compose logs -f

# Tail the logs of a single service
docker-compose logs -f items-service
----

Try it out by executing the REST-call

[source,bash]
curl http://localhost:20202/webapi/items/1 -u frank:abc | jq

[WARNING]
=====
If you get this error message

[source,json]
----
{
  "timestamp": "2020-01-05T13:40:20.096+0000",
  "status": 500,
  "error": "Internal Server Error",
  "message": "GENERAL"
}
----

then wait ~ 30 seconds and try again (so that Ribbon kicks in - the settings must be fine tuned to avoid this delay, but I haven't had time to address it yet).

This log should pop up after approximately 30 seconds, when it does, try calling again.
[source,bash]
----
gateway_1                   | 2020-01-07 15:17:08.439  INFO [gateway,,,] 1 --- [erListUpdater-0] c.netflix.config.ChainedDynamicProperty  : Flipping property: webapi.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647
----

If you then get a 504 like the below, just retry again.

[source,json]
----
{
  "timestamp": "2020-01-02T15:33:26.563+0000",
  "status": 504,
  "error": "Gateway Timeout",
  "message": "com.netflix.zuul.exception.ZuulException: Hystrix Readed time out"
}
----
=====

.Example of result, note the value of field `serviceAddress`
[source,json]
----
{
  "item": {
    "id": 1,
    "name": "Spoon",
    "serviceAddress": "4fbe43c3c0ef/172.18.0.7:8080"
  },
  "reviews": [
    {
      "id": 2,
      "type": "item",
      "typeId": 1,
      "rating": 3,
      "ratingMin": 1,
      "ratingMax": 5,
      "comment": "The spoon works until you turn it upside down, then it becomes useless",
      "serviceAddress": "427b75d73c34/172.18.0.5:8080"
    },
    {
      "id": 5,
      "type": "item",
      "typeId": 1,
      "rating": 2,
      "ratingMin": 1,
      "ratingMax": 5,
      "comment": "The one I got was completely flat",
      "serviceAddress": "427b75d73c34/172.18.0.5:8080"
    }
  ]
}
----

The `serviceAddress` shows containerId as hostname, followed by the IP-address and then the port.

It is fairly easy to spin up several instances of a service:

[source,bash]
----
# Start another instance of a service (using it's container name)
docker-compose up -d --scale items-service=2
----

Try it out by calling the application again and notice how the _hostname_ and IP in `item.serviceAddress` changes when the client loadbalancer does its work.

Here are some more commands to try out:
[source,bash]
----
# Go back to running one instance of the service
docker-compose up -d --scale items-service=1

# Shut down a single service
docker-compose up -d --scale items-service=0

# Scale several services at once
docker-compose up -d --scale items-service=2 --scale reviews-service=3

# Shut down all services and remove containers
docker-compose down
----

[TIP]
=====
For completeness: The syntax for starting a composed docker environment in non-detached mode goes like this:

[source,bash]
----
docker-compose -f <compose-file.yml> up

# If the <compose-file.yml> is named docker-compose.yml, this shourcut is enough
docker-compose up
----

The above command will start all services, and their log output will be seen directly. Pressing `Ctrl-C` will shutdown all containers.
=====

Here we are, finally, at the bottom of the pit, or at the top of the mountain, whichever you prefer. In fact, it is almost the end of the whole session. The last thing for us to do before we leave is to quickly summarize what we have been doing.

<<10-end-of-the-road.adoc#,Wrapping it up>>

